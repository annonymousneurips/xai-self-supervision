{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing and Understanding Self-Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image \n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_transforms import normal_transforms, no_shift_transforms, ig_transforms, modify_transforms\n",
    "from utils import overlay_heatmap, viz_map, show_image, deprocess, get_ssl_model\n",
    "from methods import occlusion, occlusion_context_agnositc, pairwise_occlusion, deepdream, get_difference\n",
    "from methods import create_mixed_images, averaged_transforms, sailency, smooth_grad \n",
    "from methods import get_pixel_invariance_dataset, pixel_invariance, get_gradcam, get_interactioncam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and transform images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'simclrv2'\n",
    "denorm = False\n",
    "\n",
    "ssl_model = get_ssl_model(network, '1x')\n",
    "\n",
    "if network != 'simclrv2':\n",
    "    # add ImageNet normalization to data transforms since these models expect the input to be ImageNet mean and std normalized\n",
    "    normal_transforms, no_shift_transforms, ig_transforms = modify_transforms(normal_transforms, no_shift_transforms, ig_transforms)\n",
    "    denorm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'val/images/ILSVRC2012_val_00000012.jpeg'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img1 = normal_transforms['pure'](img).unsqueeze(0).to(device)\n",
    "img2 = normal_transforms['aug'](img).unsqueeze(0).to(device)\n",
    "print(\"Similarity from model: \", nn.CosineSimilarity(dim=-1)(ssl_model(img1), ssl_model(img2)).item())\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20,5))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "axs[0].imshow(show_image(img1, denormalize = denorm))  \n",
    "axs[1].imshow(show_image(img2, denormalize = denorm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perturbation Methods\n",
    "*Conditional Occlusion, Context Agnostic Occlusion, Pairwise Occlusion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap1, heatmap2 = occlusion(img1, img2, ssl_model, w_size = 64, stride = 8, batch_size = 32)\n",
    "heatmap1_ca, heatmap2_ca = occlusion_context_agnositc(img1, img2, ssl_model, w_size = 64, stride = 8, batch_size = 32)\n",
    "heatmap1_po, heatmap2_po = pairwise_occlusion(img1, img2, ssl_model, batch_size = 32, erase_scale = (0.1, 0.3), erase_ratio = (1, 1.5), num_erases = 100)\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "added_image1 = overlay_heatmap(img1, heatmap1, denormalize = denorm)\n",
    "added_image2 = overlay_heatmap(img2, heatmap2, denormalize = denorm)\n",
    "added_image1_ca = overlay_heatmap(img1, heatmap1_ca, denormalize = denorm)\n",
    "added_image2_ca = overlay_heatmap(img2, heatmap2_ca, denormalize = denorm)\n",
    "\n",
    "axs[0, 0].set_title(\"Original and Augmented\")\n",
    "axs[0, 0].imshow(show_image(img1, denormalize = denorm))\n",
    "axs[0, 1].imshow(show_image(img2, denormalize = denorm))\n",
    "axs[1, 0].set_title(\"Conditional Occlusion\")\n",
    "axs[1, 0].imshow(added_image1)\n",
    "axs[1, 1].imshow(added_image2)\n",
    "axs[2, 0].set_title(\"Context-Agnostic Conditional Occlusion\")\n",
    "axs[2, 0].imshow(added_image1_ca)\n",
    "axs[2, 1].imshow(added_image2_ca)\n",
    "axs[3, 0].set_title(\"Pairwise Occlusion\")\n",
    "axs[3, 0].imshow((deprocess(img1, denormalize = denorm) * heatmap1_po[:,:,None]).astype('uint8'))\n",
    "axs[3, 1].imshow((deprocess(img2, denormalize = denorm) * heatmap2_po[:,:,None]).astype('uint8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Visualization\n",
    "*Maximize the cossim score with varying minmax_weight or maximize the features with varying exponentially moving average (ema)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreamed_image, detail = deepdream(img1, img2, ssl_model, optimize_score = True, up_until = 4, ema = 0.5, \n",
    "                                  reg_l2 = True, reg_l2_weight = 1e-3, use_tv = True, tv_weight = 1e-3, \n",
    "                                  minmax_weight = 0, blur = True, iterations = 20, lr = 0.01, lr_norm = True, \n",
    "                                  octave_scale = 1.4, num_octaves = 10, init_scale = 1e-2)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(20,5))\n",
    "axs.imshow(deprocess(detail, to_numpy = False))\n",
    "axs.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Difference Vizualization\n",
    "*Visualize the difference between the self-supervised model and another baseline model (e.g image classification)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_images, ssl_images = get_difference(ssl_model = ssl_model, baseline = 'imagenet', image = img2, lr = 1e4, \n",
    "                                             l2_weight = 0.1, alpha_weight = 1e-7, alpha_power = 6, tv_weight = 1e-8, \n",
    "                                             init_scale = 0.1, network = network)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(20,10))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "for aa, (in_img, ssl_img) in enumerate(zip(imagenet_images, ssl_images)):\n",
    "    axs[aa,0].imshow(deprocess(img2, denormalize = denorm))\n",
    "    axs[aa,1].imshow(deprocess(in_img))\n",
    "    axs[aa,2].imshow(deprocess(ssl_img))\n",
    "    \n",
    "axs[0,0].set_title(\"Original Image\")\n",
    "axs[0,1].set_title(\"Classification Image\")\n",
    "axs[0,2].set_title(\"Self-Supervised Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaged Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'color_jitter', 'blur', 'grayscale', 'solarize', 'combine'\n",
    "mixed_images = create_mixed_images(transform_type = 'combine', \n",
    "                                   ig_transforms = ig_transforms, \n",
    "                                   step = 0.1, \n",
    "                                   img_path = img_path, \n",
    "                                   add_noise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(mixed_images), figsize=(20,10))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "for m in range(len(mixed_images)):\n",
    "    axs[m].imshow(show_image(mixed_images[m], denormalize = denorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vanilla gradients (for comparison purposes)\n",
    "sailency1_van, sailency2_van = sailency(guided = True, ssl_model = ssl_model, \n",
    "                                        img1 = mixed_images[0], img2 = mixed_images[-1], \n",
    "                                        blur_output = True)\n",
    "\n",
    "# smooth gradients (for comparison purposes)\n",
    "sailency1_s, sailency2_s = smooth_grad(guided = True, ssl_model = ssl_model, \n",
    "                                       img1 = mixed_images[0], img2 = mixed_images[-1], \n",
    "                                       blur_output = True, steps = 50)\n",
    "\n",
    "# integrated transform\n",
    "sailency1, sailency2 = averaged_transforms(guided = True, ssl_model = ssl_model, \n",
    "                                           mixed_images = mixed_images, \n",
    "                                           blur_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "axs[0].imshow(show_image(mixed_images[0], denormalize = denorm))\n",
    "axs[0].set_title(\"Vanilla Gradients\")\n",
    "axs[1].imshow(show_image(sailency1_van.detach(), squeeze = False), cmap = plt.cm.jet)\n",
    "axs[1].imshow(show_image(mixed_images[0], denormalize = denorm), alpha=0.5)\n",
    "axs[2].imshow(show_image(mixed_images[-1], denormalize = denorm))\n",
    "axs[3].imshow(show_image(sailency2_van.detach(), squeeze = False), cmap = plt.cm.jet)\n",
    "axs[3].imshow(show_image(mixed_images[-1], denormalize = denorm), alpha=0.5)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "axs[0].imshow(show_image(mixed_images[0], denormalize = denorm))\n",
    "axs[0].set_title(\"Smooth Gradients\")\n",
    "axs[1].imshow(show_image(sailency1_s.detach(), squeeze = False), cmap = plt.cm.jet)\n",
    "axs[1].imshow(show_image(mixed_images[0], denormalize = denorm), alpha=0.5)\n",
    "axs[2].imshow(show_image(mixed_images[-1], denormalize = denorm))\n",
    "axs[3].imshow(show_image(sailency2_s.detach(), squeeze = False), cmap = plt.cm.jet)\n",
    "axs[3].imshow(show_image(mixed_images[-1], denormalize = denorm), alpha=0.5)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "axs[0].imshow(show_image(mixed_images[0], denormalize = denorm))\n",
    "axs[0].set_title(\"Integrated Transform\")\n",
    "axs[1].imshow(show_image(sailency1.detach(), squeeze = False), cmap = plt.cm.jet)\n",
    "axs[1].imshow(show_image(mixed_images[0], denormalize = denorm), alpha=0.5)\n",
    "axs[2].imshow(show_image(mixed_images[-1], denormalize = denorm))\n",
    "axs[3].imshow(show_image(sailency2.detach(), squeeze = False), cmap = plt.cm.jet)\n",
    "axs[3].imshow(show_image(mixed_images[-1], denormalize = denorm), alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples1, data_samples2, data_labels = get_pixel_invariance_dataset(img_path = img_path, num_augments = 1000, \n",
    "                                                                         batch_size =  32, \n",
    "                                                                         no_shift_transforms = no_shift_transforms, \n",
    "                                                                         ssl_model = ssl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 10, figsize=(20,10))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "for m in range(10):\n",
    "    axs[m].imshow(show_image(data_samples1[m], squeeze = False, denormalize = denorm))\n",
    "    \n",
    "fig, axs = plt.subplots(1, 10, figsize=(20,10))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "for m in range(10):\n",
    "    axs[m].imshow(show_image(data_samples2[m], squeeze = False, denormalize = denorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_heatmap = pixel_invariance(data_samples1 = data_samples1, data_samples2 = data_samples2, data_labels = data_labels,\n",
    "                               resize_transform = transforms.Resize, size = 64, epochs = 1000, learning_rate = 0.1, \n",
    "                               l1_weight = 0.2, zero_small_values = True, blur_output = True)\n",
    "\n",
    "plt.imshow(viz_map(img_path, inv_heatmap))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam1, gradcam2 = get_gradcam(ssl_model, img1, img2)\n",
    "intcam1_mean, intcam2_mean = get_interactioncam(ssl_model, img1, img2, reduction = 'mean')\n",
    "intcam1_max, intcam2_max = get_interactioncam(ssl_model, img1, img2, reduction = 'max')\n",
    "intcam1_attn, intcam2_attn = get_interactioncam(ssl_model, img1, img2, reduction = 'attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "axs[0].imshow(show_image(img1[0], squeeze = False, denormalize = denorm))\n",
    "axs[0].set_title(\"Grad-CAM\")\n",
    "axs[1].imshow(overlay_heatmap(img1, gradcam1, denormalize = denorm))\n",
    "axs[2].imshow(show_image(img2[0], squeeze = False, denormalize = denorm))\n",
    "axs[3].imshow(overlay_heatmap(img2, gradcam2, denormalize = denorm))\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "axs[0].imshow(show_image(img1[0], squeeze = False, denormalize = denorm))\n",
    "axs[0].set_title(\"Interaction-CAM Mean\")\n",
    "axs[1].imshow(overlay_heatmap(img1, intcam1_mean, denormalize = denorm))\n",
    "axs[2].imshow(show_image(img2[0], squeeze = False, denormalize = denorm))\n",
    "axs[3].imshow(overlay_heatmap(img2, intcam2_mean, denormalize = denorm))\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "axs[0].imshow(show_image(img1[0], squeeze = False, denormalize = denorm))\n",
    "axs[0].set_title(\"Interaction-CAM Max\")\n",
    "axs[1].imshow(overlay_heatmap(img1, intcam1_max, denormalize = denorm))\n",
    "axs[2].imshow(show_image(img2[0], squeeze = False, denormalize = denorm))\n",
    "axs[3].imshow(overlay_heatmap(img2, intcam2_max, denormalize = denorm))\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "axs[0].imshow(show_image(img1[0], squeeze = False, denormalize = denorm))\n",
    "axs[0].set_title(\"Interaction-CAM X-Attention\")\n",
    "axs[1].imshow(overlay_heatmap(img1, intcam1_attn, denormalize = denorm))\n",
    "axs[2].imshow(show_image(img2[0], squeeze = False, denormalize = denorm))\n",
    "axs[3].imshow(overlay_heatmap(img2, intcam2_attn, denormalize = denorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
